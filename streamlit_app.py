import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

st.set_page_config(
    page_title="IronHack Payments Cohort Analysis",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("IronHack Payments Cohort Analysis Dashboard")
st.markdown("""
This dashboard presents an interactive cohort analysis for IronHack Payments. You can explore:
- **Usage Frequency:** How often users (per unique user) use the cash advance service.
- **Incident Rate:** The rate of payment incidents (e.g. rejected, canceled) at cohort start.
- **Revenue Analysis:** Total revenue generated by each cohort over time.
- **Retention Analysis:** The percentage of original users that remain active in subsequent months.
""")

@st.cache_data
def load_processed_data():
    usage_summary = pd.read_pickle("processed_data/usage_summary.pkl")
    retention = pd.read_pickle("processed_data/retention.pkl")
    return usage_summary, retention

usage_summary, retention = load_processed_data()


@st.cache_data
def load_and_preprocess_data():
    df_cash = pd.read_csv(
        "project_dataset/extract - cash request - data analyst.csv", 
        parse_dates=[
            'created_at', 'updated_at', 'moderated_at', 
            'reimbursement_date', 'cash_request_received_date', 'money_back_date'
        ]
    )
    df_cash = df_cash.dropna(subset=['user_id'])
    
    df_cash['usage_count'] = 1
    
    incident_statuses = ['rejected', 'canceled', 'direct_debit_rejected']
    df_cash['incident'] = df_cash['status'].isin(incident_statuses).astype(int)
    
    df_cash['cohort_month'] = df_cash.groupby('user_id')['created_at'].transform('min').dt.to_period('M')

    df_cash['created_period'] = df_cash['created_at'].dt.to_period('M')

    df_cash['cohort_index'] = (df_cash['created_period'] - df_cash['cohort_month']).apply(lambda x: x.n)
    
    return df_cash

@st.cache_data
def compute_usage_summary(df):
    usage_summary = df.groupby(['cohort_month', 'cohort_index']).agg(
        total_requests=('usage_count', 'sum'),
        unique_users=('user_id', 'nunique'),
        total_incidents=('incident', 'sum'),
        total_revenue=('amount', 'sum')
    ).reset_index()
    
    usage_summary['usage_frequency'] = usage_summary['total_requests'] / usage_summary['unique_users']
    usage_summary['incident_rate'] = usage_summary['total_incidents'] / usage_summary['total_requests']
    
    
    return usage_summary

@st.cache_data
def compute_retention(df):
    cohort_sizes = df.groupby('cohort_month')['user_id'].nunique().reset_index()
    cohort_sizes.columns = ['cohort_month', 'cohort_size']
    
    cohort_data = df.groupby(['cohort_month', 'cohort_index'])['user_id'].nunique().reset_index()
    cohort_pivot = cohort_data.pivot(index='cohort_month', columns='cohort_index', values='user_id')
    
    retention = cohort_pivot.divide(cohort_sizes.set_index('cohort_month')['cohort_size'], axis=0)
    return retention

df_cash = load_and_preprocess_data()
usage_summary = compute_usage_summary(df_cash)
retention = compute_retention(df_cash)

st.sidebar.header("Select Visualization")
viz_option = st.sidebar.selectbox("Choose a visualization", 
    ["Usage Frequency Heatmap", "Incident Rate at Cohort Start", "Revenue Analysis", "Retention Analysis"]
)
if viz_option == "Usage Frequency Heatmap":
    st.subheader("Usage Frequency Heatmap")
    pivot_usage = usage_summary.pivot(index='cohort_month', columns='cohort_index', values='usage_frequency')
    fig, ax = plt.subplots(figsize=(12, 8))
    sns.heatmap(pivot_usage, annot=True, fmt=".2f", cmap="YlGnBu", ax=ax)
    ax.set_title("Usage Frequency (Requests per Unique User)")
    ax.set_xlabel("Cohort Index (Months Since First Request)")
    ax.set_ylabel("Cohort Month")
    st.pyplot(fig)

elif viz_option == "Incident Rate at Cohort Start":
    incident_rate_pivot = usage_summary.pivot(
        index='cohort_month', 
        columns='cohort_index', 
        values='incident_rate'
    )

    incident_rate_pivot = incident_rate_pivot.dropna(axis=0, how='all').dropna(axis=1, how='all')

    fig, ax = plt.subplots(figsize=(12, 8))
    sns.heatmap(
        incident_rate_pivot, 
        annot=True, 
        fmt=".2f", 
        cmap="YlOrRd",
        cbar_kws={'label': 'Incident Rate'},
        linewidths=0.5,
        linecolor='gray',
        ax=ax
    )
    ax.set_title("Incident Rate by Cohort and Month")
    ax.set_xlabel("Months since Cohort Start (Cohort Index)")
    ax.set_ylabel("Cohort Month")
    plt.xticks(rotation=0)
    plt.yticks(rotation=0)
    st.pyplot(fig)



elif viz_option == "Revenue Analysis":
    st.subheader("Revenue Analysis")
    pivot_revenue = usage_summary.pivot(index='cohort_month', columns='cohort_index', values='total_revenue')
    overall_max_index = usage_summary['cohort_index'].max()
    pivot_revenue = pivot_revenue.loc[:, pivot_revenue.columns < overall_max_index]
    fig, ax = plt.subplots(figsize=(12, 8))
    sns.heatmap(pivot_revenue, annot=True, fmt=".0f", cmap="YlOrRd",
                cbar_kws={'label': 'Total Revenue ($)'}, linewidths=0.5, linecolor='gray', ax=ax)
    ax.set_title("Total Revenue by Cohort Month and Cohort Index")
    ax.set_xlabel("Cohort Index (Months Since First Request)")
    ax.set_ylabel("Cohort Month")
    plt.xticks(rotation=0)
    plt.yticks(rotation=0)
    st.pyplot(fig)

elif viz_option == "Retention Analysis":
    st.subheader("Retention Analysis")
    st.write("Retention is calculated as the proportion of users from the original cohort (month 0) that are still active in subsequent months. A user is considered 'active' in a given month if there is at least one transaction recorded in that month.")
    st.write("Retention Table (rounded to 2 decimals):")
    st.dataframe(retention.round(2))
    
    fig, ax = plt.subplots(figsize=(12, 8))
    sns.heatmap(retention, annot=True, fmt=".2f", cmap="Blues", ax=ax)
    ax.set_title("Retention Rates by Cohort Month and Cohort Index")
    ax.set_xlabel("Cohort Index (Months Since First Request)")
    ax.set_ylabel("Cohort Month")
    st.pyplot(fig)

st.markdown("---")
st.markdown("Data processing and visualizations are implemented using best practices (e.g., caching and modular functions) to ensure that the dashboard is responsive and maintainable.")
